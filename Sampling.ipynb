{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the creditcard dataset from the following link:<br>https://github.com/AnjulaMehto/Sampling_Assignment/blob/main/Creditcard_data.csv <br>Convert this data-set into balanced class dataset. Create five samples.Apply five different sampling techniques ( Sampling1, Sampling2, Sampling3, \n",
    "Sampling4, Sampling5) on five different ML models (M1, M2, M3, M4 and M5).<br> Determine which sampling technique gives higher accuracy on which model. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 763, 1: 9})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0     0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1     0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2     1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3     1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4     2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      1  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"G:/Creditcard_data.csv\")\n",
    "print(Counter(data['Class']))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X=data.drop(['Class'],axis=1)\n",
    "Y=data['Class']\n",
    "X.head()\n",
    "Y.head()\n",
    "dict1=Counter(data['Class'])\n",
    "dict1\n",
    "zero_count=dict1[0]\n",
    "zero_count\n",
    "one_count=dict1[1]\n",
    "one_count\n",
    "list1=[0,1]\n",
    "plt.bar(dict1.keys(),dict1.values())\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Class Visualization\")\n",
    "plt.xticks([0,1])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here,in the given dataset,oversampling is done using SMOTE so as to balance the imbalanced dataset.(Synthetic Miniority Oversampling Technique is used to oversample the  miniority class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 763, 1: 763})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote=SMOTE(random_state=42)\n",
    "x_smote,y_smote=smote.fit_resample(X,Y)\n",
    "Counter(y_smote)\n",
    "x_smote.head()\n",
    "Counter(y_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.620000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.690000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.660000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.990000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>233</td>\n",
       "      <td>-0.143424</td>\n",
       "      <td>0.517932</td>\n",
       "      <td>0.731111</td>\n",
       "      <td>0.129628</td>\n",
       "      <td>0.854012</td>\n",
       "      <td>0.001878</td>\n",
       "      <td>0.422518</td>\n",
       "      <td>0.075371</td>\n",
       "      <td>-0.127180</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.086502</td>\n",
       "      <td>-0.238275</td>\n",
       "      <td>0.062436</td>\n",
       "      <td>-0.985098</td>\n",
       "      <td>-1.003529</td>\n",
       "      <td>-0.039215</td>\n",
       "      <td>0.158937</td>\n",
       "      <td>0.153083</td>\n",
       "      <td>0.992166</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>288</td>\n",
       "      <td>-0.314860</td>\n",
       "      <td>0.491771</td>\n",
       "      <td>0.951783</td>\n",
       "      <td>0.141217</td>\n",
       "      <td>0.878564</td>\n",
       "      <td>-0.195386</td>\n",
       "      <td>0.522255</td>\n",
       "      <td>0.024692</td>\n",
       "      <td>-0.130443</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053105</td>\n",
       "      <td>-0.124739</td>\n",
       "      <td>-0.007566</td>\n",
       "      <td>-0.685670</td>\n",
       "      <td>-0.698822</td>\n",
       "      <td>-0.129806</td>\n",
       "      <td>0.101392</td>\n",
       "      <td>0.092159</td>\n",
       "      <td>0.993877</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>465</td>\n",
       "      <td>-2.161259</td>\n",
       "      <td>-0.202359</td>\n",
       "      <td>0.365042</td>\n",
       "      <td>2.613566</td>\n",
       "      <td>0.923353</td>\n",
       "      <td>-0.447669</td>\n",
       "      <td>-2.330450</td>\n",
       "      <td>1.099415</td>\n",
       "      <td>-0.963817</td>\n",
       "      <td>...</td>\n",
       "      <td>0.471321</td>\n",
       "      <td>0.560975</td>\n",
       "      <td>-0.095592</td>\n",
       "      <td>-0.250085</td>\n",
       "      <td>-0.083285</td>\n",
       "      <td>0.508771</td>\n",
       "      <td>0.074280</td>\n",
       "      <td>-0.156735</td>\n",
       "      <td>0.726598</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>516</td>\n",
       "      <td>-2.181198</td>\n",
       "      <td>-1.036044</td>\n",
       "      <td>1.153616</td>\n",
       "      <td>0.342333</td>\n",
       "      <td>1.069585</td>\n",
       "      <td>-0.553986</td>\n",
       "      <td>0.288244</td>\n",
       "      <td>0.069938</td>\n",
       "      <td>-0.076396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105787</td>\n",
       "      <td>0.020804</td>\n",
       "      <td>0.293645</td>\n",
       "      <td>-0.256581</td>\n",
       "      <td>-0.126499</td>\n",
       "      <td>0.109506</td>\n",
       "      <td>-0.313804</td>\n",
       "      <td>-0.241336</td>\n",
       "      <td>180.086978</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>365</td>\n",
       "      <td>-1.073464</td>\n",
       "      <td>-1.133695</td>\n",
       "      <td>1.566331</td>\n",
       "      <td>0.681840</td>\n",
       "      <td>1.729351</td>\n",
       "      <td>0.441039</td>\n",
       "      <td>-1.034480</td>\n",
       "      <td>0.498312</td>\n",
       "      <td>0.475220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176062</td>\n",
       "      <td>0.490331</td>\n",
       "      <td>0.232206</td>\n",
       "      <td>-1.083672</td>\n",
       "      <td>-0.742202</td>\n",
       "      <td>0.509854</td>\n",
       "      <td>0.034676</td>\n",
       "      <td>0.008290</td>\n",
       "      <td>1.272031</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1526 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0        0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "1        0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
       "2        1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
       "3        1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
       "4        2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
       "...    ...       ...       ...       ...       ...       ...       ...   \n",
       "1521   233 -0.143424  0.517932  0.731111  0.129628  0.854012  0.001878   \n",
       "1522   288 -0.314860  0.491771  0.951783  0.141217  0.878564 -0.195386   \n",
       "1523   465 -2.161259 -0.202359  0.365042  2.613566  0.923353 -0.447669   \n",
       "1524   516 -2.181198 -1.036044  1.153616  0.342333  1.069585 -0.553986   \n",
       "1525   365 -1.073464 -1.133695  1.566331  0.681840  1.729351  0.441039   \n",
       "\n",
       "            V7        V8        V9  ...       V21       V22       V23  \\\n",
       "0     0.239599  0.098698  0.363787  ... -0.018307  0.277838 -0.110474   \n",
       "1    -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288   \n",
       "2     0.791461  0.247676 -1.514654  ...  0.247998  0.771679  0.909412   \n",
       "3     0.237609  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321   \n",
       "4     0.592941 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1521  0.422518  0.075371 -0.127180  ... -0.086502 -0.238275  0.062436   \n",
       "1522  0.522255  0.024692 -0.130443  ... -0.053105 -0.124739 -0.007566   \n",
       "1523 -2.330450  1.099415 -0.963817  ...  0.471321  0.560975 -0.095592   \n",
       "1524  0.288244  0.069938 -0.076396  ...  0.105787  0.020804  0.293645   \n",
       "1525 -1.034480  0.498312  0.475220  ...  0.176062  0.490331  0.232206   \n",
       "\n",
       "           V24       V25       V26       V27       V28      Amount  Class  \n",
       "0     0.066928  0.128539 -0.189115  0.133558 -0.021053  149.620000      0  \n",
       "1    -0.339846  0.167170  0.125895 -0.008983  0.014724    2.690000      1  \n",
       "2    -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.660000      0  \n",
       "3    -1.175575  0.647376 -0.221929  0.062723  0.061458  123.500000      0  \n",
       "4     0.141267 -0.206010  0.502292  0.219422  0.215153   69.990000      0  \n",
       "...        ...       ...       ...       ...       ...         ...    ...  \n",
       "1521 -0.985098 -1.003529 -0.039215  0.158937  0.153083    0.992166      1  \n",
       "1522 -0.685670 -0.698822 -0.129806  0.101392  0.092159    0.993877      1  \n",
       "1523 -0.250085 -0.083285  0.508771  0.074280 -0.156735    0.726598      1  \n",
       "1524 -0.256581 -0.126499  0.109506 -0.313804 -0.241336  180.086978      1  \n",
       "1525 -1.083672 -0.742202  0.509854  0.034676  0.008290    1.272031      1  \n",
       "\n",
       "[1526 rows x 31 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.concat([x_smote,y_smote],axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>normAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "      <td>0.617566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.306787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "      <td>2.058484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "      <td>0.453242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "      <td>0.116605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  0.090794  ... -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425 -0.166974  ... -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024 -0.054952  ... -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  0.753074  ... -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Class  normAmount  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053      0    0.617566  \n",
       "1  0.167170  0.125895 -0.008983  0.014724      1   -0.306787  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752      0    2.058484  \n",
       "3  0.647376 -0.221929  0.062723  0.061458      0    0.453242  \n",
       "4 -0.206010  0.502292  0.219422  0.215153      0    0.116605  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['normAmount'] = StandardScaler().fit_transform(np.array(data['Amount']).reshape(-1, 1))# normalising the amount column\n",
    "data = data.drop(['Time', 'Amount'], axis = 1)# Dropping Time and Amount columns as they are not relevant for prediction purpose .\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models Used"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have used 5 ML models:\n",
    "<br>\n",
    "1.XGB Classifier\n",
    "<br>\n",
    "2.Random Forest Classifier\n",
    "<br>\n",
    "3.KNN\n",
    "<br>\n",
    "4.Extra Trees Classifier\n",
    "<br>\n",
    "5.SVM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. XGB Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 1-> XGB Classifier \n",
    "def xgb(x_train,y_train,x_test,y_test):\n",
    "    model=XGBClassifier()\n",
    "    model.fit(x_train,y_train)\n",
    "    y_pred=model.predict(x_test)\n",
    "    accuracy=accuracy_score(y_test,y_pred)\n",
    "    return accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 2-> Random Forest Classifier\n",
    "def randomForest(x_train,y_train,x_test,y_test):\n",
    "    model=RandomForestClassifier(n_estimators=200)\n",
    "    model.fit(x_train,y_train)\n",
    "    y_pred=model.predict(x_test)\n",
    "    accuracy=accuracy_score(y_test,y_pred)\n",
    "    return accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 3->K Neighbors Classifier\n",
    "def KNN(x_train,y_train,x_test,y_test):\n",
    "    model=KNeighborsClassifier(n_neighbors=7)\n",
    "    model.fit(x_train,y_train)\n",
    "    y_pred=model.predict(x_test)\n",
    "    accuracy=accuracy_score(y_test,y_pred)\n",
    "    return accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 4->Extra Trees Classifier\n",
    "def extraTrees(x_train,y_train,x_test,y_test):\n",
    "    model=ExtraTreesClassifier(n_estimators=200)\n",
    "    model.fit(x_train,y_train)\n",
    "    y_pred=model.predict(x_test)\n",
    "    accuracy=accuracy_score(y_test,y_pred)\n",
    "    return accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 5->SVC\n",
    "def svmClassifier(x_train,y_train,x_test,y_test):\n",
    "    model=SVC()\n",
    "    model.fit(x_train,y_train)\n",
    "    y_pred=model.predict(x_test)\n",
    "    accuracy=accuracy_score(y_test,y_pred)\n",
    "    return accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling Techniques Used"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have used 5 sampling techniques:\n",
    "<br>\n",
    "1.Simple Random Sampling\n",
    "<br>\n",
    "2.Systematic Sampling\n",
    "<br>\n",
    "3.Stratified Sampling\n",
    "<br>\n",
    "4.Cluster Sampling\n",
    "<br>\n",
    "5.Multi-Stage Sampling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.Simple Random Sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples:  384\n"
     ]
    }
   ],
   "source": [
    "#1.Random Sampling\n",
    "noOfSamples=int((1.96*1.96*0.5*0.5)/(0.05*0.05))#Assumed Z=1.96,p=0.5 and E=0.05\n",
    "print(\"Number of samples: \",noOfSamples)\n",
    "random_sample1=data.sample(n=noOfSamples,random_state=2)\n",
    "X1=random_sample1.drop(['Class'],axis=1)\n",
    "Y1=random_sample1['Class']\n",
    "Y1\n",
    "X1\n",
    "x_train,x_test,y_train,y_test=train_test_split(X1,Y1,test_size=0.3,random_state=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of XGB Classifier:  0.9741379310344828\n",
      "Accuracy of Random Forest Classifier:  1.0\n",
      "Accuracy of KNN Classifier:  0.896551724137931\n",
      "Accuracy of Extra Trees Classifier:  1.0\n",
      "Accuracy of SVM Classifier:  0.9827586206896551\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of XGB Classifier: \",xgb(x_train,y_train,x_test,y_test))\n",
    "print(\"Accuracy of Random Forest Classifier: \",randomForest(x_train,y_train,x_test,y_test))\n",
    "print(\"Accuracy of KNN Classifier: \",KNN(x_train,y_train,x_test,y_test))\n",
    "print(\"Accuracy of Extra Trees Classifier: \",extraTrees(x_train,y_train,x_test,y_test))\n",
    "print(\"Accuracy of SVM Classifier: \",svmClassifier(x_train,y_train,x_test,y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.Systematic Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.Systematic Sampling\n",
    "systematic_sample=data.iloc[::4]\n",
    "systematic_sample\n",
    "X2=random_sample1.drop(['Class'],axis=1)\n",
    "Y2=random_sample1['Class']\n",
    "Y2\n",
    "X2\n",
    "x_train1,x_test1,y_train1,y_test1=train_test_split(X2,Y2,test_size=0.3,random_state=20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of XGB Classifier:  0.9655172413793104\n",
      "Accuracy of Random Forest Classifier:  0.9913793103448276\n",
      "Accuracy of KNN Classifier:  0.9137931034482759\n",
      "Accuracy of Extra Trees Classifier:  0.9913793103448276\n",
      "Accuracy of SVM Classifier:  1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of XGB Classifier: \",xgb(x_train1,y_train1,x_test1,y_test1))\n",
    "print(\"Accuracy of Random Forest Classifier: \",randomForest(x_train1,y_train1,x_test1,y_test1))\n",
    "print(\"Accuracy of KNN Classifier: \",KNN(x_train1,y_train1,x_test1,y_test1))\n",
    "print(\"Accuracy of Extra Trees Classifier: \",extraTrees(x_train1,y_train1,x_test1,y_test1))\n",
    "print(\"Accuracy of SVM Classifier: \",svmClassifier(x_train1,y_train1,x_test1,y_test1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.Stratified Sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples:  384\n"
     ]
    }
   ],
   "source": [
    "#3. Stratified Sampling\n",
    "noOfSamples=int((1.96*1.96*0.5*0.5*1*1)/(0.05*0.05))#Assumed Z=1.96,p=0.5 and E=0.05,S=1\n",
    "print(\"Number of samples: \",noOfSamples)\n",
    "# print(len(data))\n",
    "zero_data=data.loc[data['Class']==0]\n",
    "zero_data\n",
    "zero_new_data=zero_data.sample(n=375,random_state=15)\n",
    "zero_new_data\n",
    "one_data=data.loc[data['Class']==1]\n",
    "one_data\n",
    "one_new_data=one_data.sample(n=375,random_state=15)\n",
    "one_new_data\n",
    "new_data=pd.concat([zero_new_data,one_new_data],axis=0)\n",
    "new_data\n",
    "X3=new_data.drop(['Class'],axis=1)\n",
    "Y3=new_data['Class']\n",
    "x_train2,x_test2,y_train2,y_test2=train_test_split(X3,Y3,test_size=0.3,random_state=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of XGB Classifier:  1.0\n",
      "Accuracy of Random Forest Classifier:  1.0\n",
      "Accuracy of KNN Classifier:  0.9422222222222222\n",
      "Accuracy of Extra Trees Classifier:  1.0\n",
      "Accuracy of SVM Classifier:  0.9644444444444444\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of XGB Classifier: \",xgb(x_train2,y_train2,x_test2,y_test2))\n",
    "print(\"Accuracy of Random Forest Classifier: \",randomForest(x_train2,y_train2,x_test2,y_test2))\n",
    "print(\"Accuracy of KNN Classifier: \",KNN(x_train2,y_train2,x_test2,y_test2))\n",
    "print(\"Accuracy of Extra Trees Classifier: \",extraTrees(x_train2,y_train2,x_test2,y_test2))\n",
    "print(\"Accuracy of SVM Classifier: \",svmClassifier(x_train2,y_train2,x_test2,y_test2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.Cluster Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.Cluster Sampling\n",
    "clusters = []\n",
    "cluster_sample= pd.DataFrame()\n",
    "for i in range(10) :\n",
    "    cluster = data.sample(n=100,ignore_index=True,random_state=i)\n",
    "    clusters.append(cluster)\n",
    "for i in range(5) :\n",
    "    cluster_sample = pd.concat([cluster_sample,clusters[math.floor(random.random()*10)]])\n",
    "cluster_sample\n",
    "clusters\n",
    "X4=cluster_sample.drop(['Class'],axis=1)\n",
    "Y4=cluster_sample['Class']\n",
    "x_train3,x_test3,y_train3,y_test3=train_test_split(X4,Y4,test_size=0.3,random_state=15)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of XGB Classifier:  0.98\n",
      "Accuracy of Random Forest Classifier:  0.9866666666666667\n",
      "Accuracy of KNN Classifier:  0.9266666666666666\n",
      "Accuracy of Extra Trees Classifier:  1.0\n",
      "Accuracy of SVM Classifier:  0.9866666666666667\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of XGB Classifier: \",xgb(x_train3,y_train3,x_test3,y_test3))\n",
    "print(\"Accuracy of Random Forest Classifier: \",randomForest(x_train3,y_train3,x_test3,y_test3))\n",
    "print(\"Accuracy of KNN Classifier: \",KNN(x_train3,y_train3,x_test3,y_test3))\n",
    "print(\"Accuracy of Extra Trees Classifier: \",extraTrees(x_train3,y_train3,x_test3,y_test3))\n",
    "print(\"Accuracy of SVM Classifier: \",svmClassifier(x_train3,y_train3,x_test3,y_test3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.Multi-Stage Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Multi-Stage Sampling\n",
    "zero_data1=data.loc[data['Class']==0]\n",
    "zero_data1\n",
    "zero_new_data1=zero_data1.sample(n=375,random_state=15)\n",
    "zero_new_data1\n",
    "one_data1=data.loc[data['Class']==1]\n",
    "one_data1\n",
    "one_new_data1=one_data1.sample(n=375,random_state=15)\n",
    "one_new_data1\n",
    "new_data1=pd.concat([zero_new_data1,one_new_data1],axis=0)\n",
    "new_data1\n",
    "multi_stage_sample=new_data1.sample(n=500,random_state=31)\n",
    "X4=multi_stage_sample.drop(['Class'],axis=1)\n",
    "Y4=multi_stage_sample['Class']\n",
    "x_train4,x_test4,y_train4,y_test4=train_test_split(X4,Y4,test_size=0.3,random_state=19)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of XGB Classifier:  0.98\n",
      "Accuracy of Random Forest Classifier:  0.9866666666666667\n",
      "Accuracy of KNN Classifier:  0.8533333333333334\n",
      "Accuracy of Extra Trees Classifier:  1.0\n",
      "Accuracy of SVM Classifier:  0.9533333333333334\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of XGB Classifier: \",xgb(x_train4,y_train4,x_test4,y_test4))\n",
    "print(\"Accuracy of Random Forest Classifier: \",randomForest(x_train4,y_train4,x_test4,y_test4))\n",
    "print(\"Accuracy of KNN Classifier: \",KNN(x_train4,y_train4,x_test4,y_test4))\n",
    "print(\"Accuracy of Extra Trees Classifier: \",extraTrees(x_train4,y_train4,x_test4,y_test4))\n",
    "print(\"Accuracy of SVM Classifier: \",svmClassifier(x_train4,y_train4,x_test4,y_test4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|                            | Simple Random Sampling| Systematic Sampling | Stratified Sampling | Cluster Sampling |Multi-Stage Sampling|\n",
    "| ---------------------------| --------------------- | --------------------| --------------------| -----------------|--------------------| \n",
    "|XGB Classifier              |0.9741379310344828     |0.9655172413793104   |1.0                  |0.98              | 0.98               |\n",
    "|Random Forest Classifier    |1.0                    |0.9913793103448276   |1.0                  |0.9866666666666667| 0.9866666666666667 |\n",
    "|KNN Classifier              |0.896551724137931      |0.9137931034482759   |0.9422222222222222   |0.9266666666666666| 0.8533333333333334 |\n",
    "|Extra Trees Classifier      |1.0                    |0.9913793103448276   |1.0                  |1.0               | 1.0                |\n",
    "|SVM Classifier              |0.9827586206896551     |1.0                  |0.9644444444444444   |0.9866666666666667| 0.9533333333333334 |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the results:-\n",
    "<br>\n",
    "1.Simple Random Sampling gives higher accuracy when Random Forest Classifier and Extra Trees Classifier is used.\n",
    "<br>\n",
    "2.Systematic Sampling gives higher accuracy when SVM Classifier is used.\n",
    "<br>\n",
    "3.Stratified Sampling gives higher accuracy when XGB Classifier,Random Forest Classifier and Extra Trees Classifier are used.\n",
    "<br>\n",
    "4.Cluster Sampling gives higher accuracy when Extra Trees Classifier are used.\n",
    "<br>\n",
    "5.Multi-Stage Sampling gives higher accuracy when Extra Trees Classifier is used."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1fbb152377eda34f45ca96b3fb23ef4bafae75342ed8936eef804eca9d25f8ef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
